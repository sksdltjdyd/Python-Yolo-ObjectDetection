import pyrealsense2 as rs
import numpy as np
import cv2
from ultralytics import YOLO
import time
from collections import deque
from pythonosc import udp_client

class UltimateDepthBallTracker:
    def __init__(self):
        # RealSense ì´ˆê¸°í™”
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        
        profile = self.pipeline.start(config)
        
        # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
        self.depth_intrinsics = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()
        
        # ì •ë ¬ ê°ì²´
        self.align = rs.align(rs.stream.color)
        
        # í•„í„°
        self.spatial = rs.spatial_filter()
        self.temporal = rs.temporal_filter()
        self.hole_filling = rs.hole_filling_filter()
        
        # YOLO ëª¨ë¸
        self.model = YOLO('yolov8n.pt')
        
        # OSC (Unreal í†µì‹ ) - ì„ íƒì 
        try:
            self.osc_client = udp_client.SimpleUDPClient("127.0.0.1", 8000)
        except:
            self.osc_client = None
            print("OSC ì—°ê²° ì‹¤íŒ¨ - ê³„ì† ì§„í–‰")
        
        # ë²½ ì„¤ì •
        self.wall_distance = None  # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”
        self.collision_threshold = 50  # 50mm
        
        # ì¶”ì  ë°ì´í„° (ê° ê³µë³„)
        self.balls = {}
        self.next_ball_id = 0
        
        # ì¶©ëŒ ê¸°ë¡
        self.collisions = []
        self.last_collision_time = 0
        
    def calibrate_wall(self):
        """ë²½ ê±°ë¦¬ ìë™ ìº˜ë¦¬ë¸Œë ˆì´ì…˜"""
        print("ë²½ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ - 3ì´ˆ í›„ ì‹œì‘...")
        time.sleep(3)
        
        depths = []
        for _ in range(30):
            frames = self.pipeline.wait_for_frames()
            aligned_frames = self.align.process(frames)
            depth_frame = aligned_frames.get_depth_frame()
            
            # í•„í„° ì ìš©
            depth_frame = self.spatial.process(depth_frame)
            depth_frame = self.temporal.process(depth_frame)
            
            depth_image = np.asanyarray(depth_frame.get_data())
            
            # ì¤‘ì•™ ì˜ì—­ ê¹Šì´
            h, w = depth_image.shape
            center_region = depth_image[h//2-50:h//2+50, w//2-50:w//2+50]
            valid_depths = center_region[center_region > 0]
            
            if len(valid_depths) > 0:
                depths.append(np.median(valid_depths))
        
        if depths:
            self.wall_distance = np.median(depths)
            print(f"âœ… ë²½ ê±°ë¦¬: {self.wall_distance:.0f}mm")
            return True
        return False
    
    def pixel_to_3d_point(self, x, y, depth):
        """2D í”½ì…€ì„ 3D ì¢Œí‘œë¡œ ë³€í™˜ - numpy ë°°ì—´ ë°˜í™˜"""
        point = rs.rs2_deproject_pixel_to_point(
            self.depth_intrinsics, [x, y], depth
        )
        return np.array(point)  # âš ï¸ ì¤‘ìš”: numpy ë°°ì—´ë¡œ ë°˜í™˜
    
    def calculate_3d_velocity(self, positions, timestamps):
        """ì‹¤ì œ 3D ì†ë„ ê³„ì‚° (m/s) - ìˆ˜ì •ëœ ë²„ì „"""
        if len(positions) < 2:
            return 0, np.array([0, 0, 0])
        
        # âš ï¸ ì¤‘ìš”: dequeë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        positions_array = np.array(list(positions))
        timestamps_array = np.array(list(timestamps))
        
        # ìŠ¤ë¬´ë”©ì„ ìœ„í•´ ìµœê·¼ 3ê°œ ìœ„ì¹˜ ì‚¬ìš©
        if len(positions_array) >= 3:
            p1 = np.mean(positions_array[-3:-1], axis=0)
            p2 = positions_array[-1]
            dt = timestamps_array[-1] - timestamps_array[-3]
        else:
            p1 = positions_array[-2]
            p2 = positions_array[-1]
            dt = timestamps_array[-1] - timestamps_array[-2]
        
        if dt > 0:
            # numpy ë°°ì—´ì´ë¯€ë¡œ ì—°ì‚° ê°€ëŠ¥
            velocity_vector = (p2 - p1) / dt / 1000  # mm/s â†’ m/s
            speed = np.linalg.norm(velocity_vector)
            return speed, velocity_vector
        
        return 0, np.array([0, 0, 0])
    
    def predict_collision(self, ball_data):
        """ë²½ ì¶©ëŒ ì˜ˆì¸¡"""
        if len(ball_data['positions']) < 2:
            return None
        
        # í˜„ì¬ ìœ„ì¹˜ (numpy ë°°ì—´)
        positions_array = np.array(list(ball_data['positions']))
        current_pos = positions_array[-1]
        
        # ì†ë„ ê³„ì‚°
        speed, velocity = self.calculate_3d_velocity(
            ball_data['positions'], 
            ball_data['timestamps']
        )
        
        # Zì¶• ì†ë„ (ë²½ ë°©í–¥)
        if velocity[2] <= 0.01:  # ë²½ìœ¼ë¡œ ì›€ì§ì´ì§€ ì•ŠìŒ
            return None
        
        # ë²½ê¹Œì§€ ì‹œê°„ ê³„ì‚°
        if self.wall_distance:
            time_to_wall = (self.wall_distance - current_pos[2]) / (velocity[2] * 1000)
            
            if 0 < time_to_wall < 2:  # 2ì´ˆ ì´ë‚´ ì¶©ëŒ ì˜ˆìƒ
                # ì¶©ëŒ ì˜ˆìƒ ìœ„ì¹˜
                hit_x = current_pos[0] + velocity[0] * 1000 * time_to_wall
                hit_y = current_pos[1] + velocity[1] * 1000 * time_to_wall
                
                return {
                    'time_to_impact': time_to_wall,
                    'impact_position': (hit_x, hit_y),
                    'impact_velocity': speed,
                    'confidence': min(1.0, 2.0 - time_to_wall)
                }
        
        return None
    
    def detect_collision(self, ball_data):
        """ì‹¤ì œ ì¶©ëŒ ê°ì§€"""
        if len(ball_data['positions']) < 3:
            return False, None
        
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        positions_array = np.array(list(ball_data['positions']))
        current_depth = positions_array[-1][2]
        
        # 1. ë²½ ê·¼ì ‘ ì²´í¬
        if self.wall_distance and abs(current_depth - self.wall_distance) < self.collision_threshold:
            
            # 2. ì†ë„ ë³€í™” ì²´í¬ (ì¶©ëŒ ì‹œ ê¸‰ë³€)
            v1 = positions_array[-2][2] - positions_array[-3][2]
            v2 = positions_array[-1][2] - positions_array[-2][2]
            
            # ê°ì† ë˜ëŠ” ë°˜ëŒ€ ë°©í–¥
            if v1 > 0 and v2 <= 0:  # ë²½ìœ¼ë¡œ ê°€ë‹¤ê°€ ë©ˆì¶”ê±°ë‚˜ íŠ•ê¹€
                
                # ì¶©ëŒ ê°•ë„ ê³„ì‚°
                speed, _ = self.calculate_3d_velocity(
                    ball_data['positions'], 
                    ball_data['timestamps']
                )
                
                collision_data = {
                    'ball_id': ball_data['id'],
                    'position': positions_array[-1].tolist(),  # ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    'impact_speed': speed,
                    'timestamp': time.time()
                }
                
                return True, collision_data
        
        return False, None
    
    def track_ball(self, detection, depth_image, current_time):
        """ê°œë³„ ê³µ ì¶”ì """
        cx, cy = detection['center']
        
        # ê¹Šì´ ê°’ (ì¤‘ì‹¬ ì£¼ë³€ í‰ê· )
        roi_size = 5
        y1 = max(0, cy - roi_size)
        y2 = min(depth_image.shape[0], cy + roi_size)
        x1 = max(0, cx - roi_size)
        x2 = min(depth_image.shape[1], cx + roi_size)
        
        roi_depths = depth_image[y1:y2, x1:x2]
        valid_depths = roi_depths[roi_depths > 0]
        
        if len(valid_depths) == 0:
            return None
        
        depth = np.median(valid_depths)
        
        # 3D ìœ„ì¹˜ ê³„ì‚° (numpy ë°°ì—´ë¡œ)
        point_3d = self.pixel_to_3d_point(cx, cy, depth)
        
        # ê°€ì¥ ê°€ê¹Œìš´ ê¸°ì¡´ ê³µ ì°¾ê¸°
        matched_id = self.match_ball(point_3d)
        
        if matched_id is None:
            # ìƒˆ ê³µ ìƒì„±
            matched_id = self.next_ball_id
            self.next_ball_id += 1
            
            self.balls[matched_id] = {
                'id': matched_id,
                'positions': deque(maxlen=30),
                'timestamps': deque(maxlen=30),
                'pixel_positions': deque(maxlen=30),
                'color': tuple(np.random.randint(0, 255, 3).tolist())
            }
        
        # ë°ì´í„° ì—…ë°ì´íŠ¸
        ball = self.balls[matched_id]
        ball['positions'].append(point_3d)  # numpy ë°°ì—´ ì €ì¥
        ball['timestamps'].append(current_time)
        ball['pixel_positions'].append((cx, cy))
        ball['last_seen'] = current_time
        ball['current_depth'] = depth
        
        return matched_id
    
    def match_ball(self, point_3d, threshold=200):
        """3D ê±°ë¦¬ ê¸°ë°˜ ê³µ ë§¤ì¹­"""
        min_dist = float('inf')
        matched_id = None
        
        for ball_id, ball in self.balls.items():
            if len(ball['positions']) > 0:
                # ë§ˆì§€ë§‰ ìœ„ì¹˜ì™€ 3D ê±°ë¦¬
                last_pos = np.array(ball['positions'][-1])  # numpy ë°°ì—´ë¡œ ë³€í™˜
                dist = np.linalg.norm(point_3d - last_pos)
                
                # ì‹œê°„ ì°¨ì´ ê³ ë ¤ (ì˜¤ë˜ëœ ê³µì€ ë§¤ì¹­ ì•ˆí•¨)
                time_diff = time.time() - ball.get('last_seen', 0)
                if time_diff < 1.0 and dist < min_dist and dist < threshold:
                    min_dist = dist
                    matched_id = ball_id
        
        return matched_id
    
    def visualize_tracking(self, color_image, depth_image):
        """ì¶”ì  ê²°ê³¼ ì‹œê°í™”"""
        vis_image = color_image.copy()
        h, w = vis_image.shape[:2]
        
        # ì •ë³´ íŒ¨ë„
        info_panel = np.zeros((h, 400, 3), dtype=np.uint8)
        info_panel[:] = (30, 30, 30)
        
        # ë²½ ê±°ë¦¬ í‘œì‹œ
        if self.wall_distance:
            cv2.putText(info_panel, f"Wall: {self.wall_distance:.0f}mm", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            cv2.putText(info_panel, "Wall: Not Calibrated", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # ê° ê³µ ì²˜ë¦¬
        y_offset = 60
        for ball_id, ball in self.balls.items():
            if len(ball['positions']) < 1:
                continue
                
            # ìµœê·¼ ë³¸ ì‹œê°„ ì²´í¬
            if time.time() - ball.get('last_seen', 0) > 1.0:
                continue
            
            # 3D ì •ë³´
            current_pos = np.array(ball['positions'][-1])  # numpy ë°°ì—´ë¡œ
            speed, velocity = self.calculate_3d_velocity(
                ball['positions'], 
                ball['timestamps']
            )
            
            # í”½ì…€ ìœ„ì¹˜
            if len(ball['pixel_positions']) > 0:
                px, py = ball['pixel_positions'][-1]
                
                # ê³µ í‘œì‹œ
                cv2.circle(vis_image, (px, py), 15, ball['color'], 2)
                
                # ID í‘œì‹œ
                cv2.putText(vis_image, f"ID:{ball_id}", 
                           (px - 20, py - 20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, ball['color'], 2)
                
                # ì†ë„ ë²¡í„° ê·¸ë¦¬ê¸°
                if speed > 0.1:
                    end_x = int(px + velocity[0] * 100)
                    end_y = int(py + velocity[1] * 100)
                    cv2.arrowedLine(vis_image, (px, py), (end_x, end_y),
                                   (255, 0, 0), 2, tipLength=0.3)
                
                # 3D ì •ë³´ í‘œì‹œ
                info_text = f"Depth: {current_pos[2]:.0f}mm"
                cv2.putText(vis_image, info_text, (px - 30, py + 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 0), 1)
            
            # ê¶¤ì  ê·¸ë¦¬ê¸°
            if len(ball['pixel_positions']) > 1:
                pts = np.array(list(ball['pixel_positions']), dtype=np.int32)
                for i in range(1, len(pts)):
                    thickness = int(i / len(pts) * 3) + 1
                    cv2.line(vis_image, tuple(pts[i-1]), tuple(pts[i]),
                            ball['color'], thickness)
            
            # ì¶©ëŒ ì˜ˆì¸¡
            collision_pred = self.predict_collision(ball)
            if collision_pred:
                if len(ball['pixel_positions']) > 0:
                    px, py = ball['pixel_positions'][-1]
                    cv2.putText(vis_image, 
                               f"Impact in {collision_pred['time_to_impact']:.1f}s",
                               (px - 40, py - 40),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
            
            # ì¶©ëŒ ê°ì§€
            is_collision, collision_data = self.detect_collision(ball)
            if is_collision:
                if len(ball['pixel_positions']) > 0:
                    px, py = ball['pixel_positions'][-1]
                    # ì¶©ëŒ ì´í™íŠ¸
                    cv2.circle(vis_image, (px, py), 30, (0, 0, 255), 3)
                    cv2.putText(vis_image, "COLLISION!", (px - 40, py - 60),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                # OSC ì „ì†¡
                if self.osc_client:
                    self.send_collision_to_unreal(collision_data)
                
                # ê¸°ë¡
                if time.time() - self.last_collision_time > 0.5:  # ì¤‘ë³µ ë°©ì§€
                    self.collisions.append(collision_data)
                    self.last_collision_time = time.time()
            
            # ì •ë³´ íŒ¨ë„ì— ê³µ ì •ë³´ ì¶”ê°€
            cv2.putText(info_panel, f"Ball {ball_id}:", 
                       (10, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.5, ball['color'], 1)
            cv2.putText(info_panel, f"  Speed: {speed:.2f} m/s", 
                       (10, y_offset + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
            cv2.putText(info_panel, f"  Pos: X:{current_pos[0]:.0f} Y:{current_pos[1]:.0f} Z:{current_pos[2]:.0f}", 
                       (10, y_offset + 40), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (200, 200, 200), 1)
            
            y_offset += 70
        
        # ì¶©ëŒ íˆìŠ¤í† ë¦¬
        cv2.putText(info_panel, f"Total Collisions: {len(self.collisions)}", 
                   (10, h - 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ì»¨íŠ¸ë¡¤ ì•ˆë‚´
        cv2.putText(info_panel, "[C] Calibrate | [R] Reset | [Q] Quit", 
                   (10, h - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)
        
        # ê¹Šì´ ì»¬ëŸ¬ë§µ
        depth_colormap = cv2.applyColorMap(
            cv2.convertScaleAbs(depth_image, alpha=0.03),
            cv2.COLORMAP_JET
        )
        
        # ê²°í•©
        combined = np.hstack([vis_image, depth_colormap, info_panel])
        
        return combined
    
    def send_collision_to_unreal(self, collision_data):
        """Unreal Engineìœ¼ë¡œ ì¶©ëŒ ë°ì´í„° ì „ì†¡"""
        if self.osc_client:
            try:
                self.osc_client.send_message("/ball/collision", [
                    collision_data['ball_id'],
                    collision_data['position'][0],  # X
                    collision_data['position'][1],  # Y
                    collision_data['position'][2],  # Z
                    collision_data['impact_speed'],
                    collision_data['timestamp']
                ])
            except:
                pass
    
    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        print("=" * 50)
        print("Ultimate Depth Ball Tracker")
        print("=" * 50)
        print("'C'ë¥¼ ëˆŒëŸ¬ ë²½ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì‹œì‘")
        print("=" * 50)
        
        cv2.namedWindow('3D Ball Tracking', cv2.WINDOW_NORMAL)
        
        try:
            while True:
                # í”„ë ˆì„ íšë“
                frames = self.pipeline.wait_for_frames()
                aligned_frames = self.align.process(frames)
                
                depth_frame = aligned_frames.get_depth_frame()
                color_frame = aligned_frames.get_color_frame()
                
                if not depth_frame or not color_frame:
                    continue
                
                # í•„í„° ì ìš©
                depth_frame = self.spatial.process(depth_frame)
                depth_frame = self.temporal.process(depth_frame)
                depth_frame = self.hole_filling.process(depth_frame)
                
                # numpy ë³€í™˜
                depth_image = np.asanyarray(depth_frame.get_data())
                color_image = np.asanyarray(color_frame.get_data())
                
                current_time = time.time()
                
                # YOLO ê²€ì¶œ
                results = self.model(color_image, stream=True, conf=0.5, verbose=False)
                
                detections = []
                for r in results:
                    if r.boxes is not None:
                        for box in r.boxes:
                            cls = int(box.cls[0])
                            
                            # sports ball í´ë˜ìŠ¤
                            if self.model.names[cls] in ['sports ball', 'ball', 'tennis ball']:
                                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                                cx = int((x1 + x2) / 2)
                                cy = int((y1 + y2) / 2)
                                
                                detections.append({
                                    'center': (cx, cy),
                                    'bbox': (int(x1), int(y1), int(x2), int(y2)),
                                    'confidence': float(box.conf[0])
                                })
                
                # ê° ê²€ì¶œëœ ê³µ ì¶”ì 
                for detection in detections:
                    self.track_ball(detection, depth_image, current_time)
                
                # ì‹œê°í™”
                vis_frame = self.visualize_tracking(color_image, depth_image)
                cv2.imshow('3D Ball Tracking', vis_frame)
                
                # í‚¤ ì…ë ¥ ì²˜ë¦¬
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('c'):
                    self.calibrate_wall()
                elif key == ord('r'):
                    self.balls.clear()
                    self.collisions.clear()
                    print("âœ¨ ì´ˆê¸°í™” ì™„ë£Œ")
                elif key == ord('s'):
                    # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
                    timestamp = time.strftime("%Y%m%d_%H%M%S")
                    cv2.imwrite(f"tracking_{timestamp}.jpg", vis_frame)
                    print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: tracking_{timestamp}.jpg")
                    
        except Exception as e:
            print(f"ì—ëŸ¬ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            
        finally:
            self.pipeline.stop()
            cv2.destroyAllWindows()
            print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")

if __name__ == "__main__":
    try:
        tracker = UltimateDepthBallTracker()
        tracker.run()
    except Exception as e:
        print(f"ì´ˆê¸°í™” ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()