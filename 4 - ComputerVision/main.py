# Import required libraries
from ultralytics import YOLO
import cv2
import cvzone
import math
import pickle
import numpy as np
import pyrealsense2 as rs
import time

# --- 1. ê¸°ë³¸ ì„¤ì • ---
camWidth, camHeight = 640, 480
confidence = 0.70
yoloModelPath = "C:/Users/User/Documents/Git/Python-Yolo-ObjectDetection/Yolo-Weights/Ball.pt"
classNames = ['ball']
mode = "circle"
calibrationFilePath = 'realsense_calibration_data.p' 
scale = 3
camFPS = 60
ballArea = {"min": 1300, "max": 2500}

# --- 2. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒì¼ ë¡œë“œ ---
try:
    with open(calibrationFilePath, 'rb') as fileObj:
        points = pickle.load(fileObj)
    print(f"âœ… Calibration file '{calibrationFilePath}' loaded.")
except FileNotFoundError:
    print(f"âŒ ERROR: Calibration file not found at '{calibrationFilePath}'")
    print("Please run the calibration script first to generate the file.")
    exit()

# --- 3. ì¶œë ¥ ì´ë¯¸ì§€ ë° ë°ì´í„° ì´ˆê¸°í™” ---
imgOutput = np.zeros((1080, 1920, 3), np.uint8)
collision_points = [] 
tracked_ball_last_pos = None 

# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ìš© ë³€ìˆ˜ë¥¼ ë³„ë„ë¡œ ê´€ë¦¬
circles = np.zeros((4, 2), int)
counter = 0

# --- 4. RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™” ---
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, camWidth, camHeight, rs.format.bgr8, 60)
try:
    pipeline.start(config)
    print("âœ… RealSense camera started.")
except Exception as e:
    print(f"âŒ Failed to start RealSense camera: {e}")
    exit()

# --- 5. YOLO ëª¨ë¸ ë¡œë“œ ë° FPS ê³„ì‚° ë³€ìˆ˜ ---
model = YOLO(yoloModelPath)
fps_start_time = time.time()
fps_frame_count = 0
fps = 0

# --- 6. í•¨ìˆ˜ ì •ì˜ ---
def warpImage(imgMain, circles, width, height):
    """ì´ë¯¸ì§€ë¥¼ íˆ¬ì‹œ ë³€í™˜í•˜ì—¬ ìœ„ì—ì„œ ë³¸ ê²ƒì²˜ëŸ¼ ë§Œë“­ë‹ˆë‹¤."""
    pts1 = np.float32([circles[0], circles[1], circles[2], circles[3]])
    pts2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])
    matrix = cv2.getPerspectiveTransform(pts1, pts2)
    imgWarped = cv2.warpPerspective(imgMain, matrix, (width, height))
    return imgWarped

def detectObject(imgMain):
    """YOLOë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤."""
    results = model(imgMain, stream=False, verbose=False, conf=confidence)
    objects = []
    for r in results:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            center = (x1 + (x2 - x1) // 2, y1 + (y2 - y1) // 2)
            cv2.rectangle(imgMain, (x1, y1), (x2, y2), (0, 255, 0), 2)
            objects.append({'center': center})
    return imgMain, objects

def mousePoints(event, x, y, flags, param):
    """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¬ì„¤ì • ëª¨ë“œë¥¼ ìœ„í•œ ë§ˆìš°ìŠ¤ ì½œë°± í•¨ìˆ˜"""
    global counter
    # 4ê°œ ì´ìƒì˜ ì ì´ ì°íˆì§€ ì•Šë„ë¡ ë°©ì§€
    if event == cv2.EVENT_LBUTTONDOWN and counter < 4:
        circles[counter] = (x, y)
        counter += 1
        print("Clicked points:")
        print(circles[:counter])


# --- 7. ë©”ì¸ ë£¨í”„ ---
# ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ í”Œë˜ê·¸ ì¶”ê°€
is_calibrating = False 

try:
    while True:
        # RealSense í”„ë ˆì„ ì½ê¸°
        frames = pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        if not color_frame:
            continue
        img = np.asanyarray(color_frame.get_data())

        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œì¼ ë•Œì™€ ì•„ë‹ ë•Œë¥¼ ë¶„ë¦¬
        if is_calibrating:
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì¤‘ì—ëŠ” ì ë§Œ ì°ê³  í‘œì‹œ
            for i in range(counter):
                cv2.circle(img, (circles[i][0], circles[i][1]), 5, (0, 255, 0), cv2.FILLED)
            
            if counter == 4:
                # 4ê°œì˜ ì ì´ ë‹¤ ì°íˆë©´, ìƒˆë¡œìš´ ì¢Œí‘œë¥¼ points ë³€ìˆ˜ì— ì €ì¥í•˜ê³  ëª¨ë“œ ì¢…ë£Œ
                points = circles.copy()
                with open(calibrationFilePath, 'wb') as fileObj:
                    pickle.dump(points, fileObj)
                print("âœ… New calibration points saved!")
                is_calibrating = False
                counter = 0 # ì¹´ìš´í„° ì´ˆê¸°í™”
        else:
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œê°€ ì•„ë‹ ë•Œ (ì¼ë°˜ ì¶”ì  ëª¨ë“œ)
            imgProjector = warpImage(img, points, camWidth, camHeight)
            imgWithObjects, objects = detectObject(imgProjector)

            if objects:
                current_ball_center = objects[0]['center']
                tracked_ball_last_pos = current_ball_center
            else:
                if tracked_ball_last_pos is not None:
                    collision_x = int(tracked_ball_last_pos[0] * scale)
                    collision_y = int(tracked_ball_last_pos[1] * scale)
                    collision_points.append((collision_x, collision_y))
                    tracked_ball_last_pos = None

            for point in collision_points:
                cv2.circle(imgOutput, point, 15, (0, 0, 255), cv2.FILLED)

            cv2.imshow("Projector View (Warped)", imgWithObjects)
            cv2.imshow("Collision Wall", imgOutput)

        # ê³µí†µ ë¡œì§: FPS ê³„ì‚° ë° ì›ë³¸ ì´ë¯¸ì§€ í‘œì‹œ
        fps_frame_count += 1
        if time.time() - fps_start_time >= 1.0:
            fps = fps_frame_count
            fps_frame_count = 0
            fps_start_time = time.time()
        
        # í˜„ì¬ ëª¨ë“œì— ëŒ€í•œ ì•ˆë‚´ ë¬¸êµ¬ í‘œì‹œ
        if is_calibrating:
            cv2.putText(img, f"CALIBRATING: Click {4 - counter} more points", (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
        else:
            cv2.putText(img, "TRACKING MODE", (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        cv2.putText(img, f"FPS: {int(fps)}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.imshow("Original Image (RealSense)", img)
        cv2.setMouseCallback("Original Image (RealSense)", mousePoints)

        key = cv2.waitKey(1) & 0xFF
        if key == ord('r'):
            imgOutput.fill(0)
            collision_points.clear()
            print("âœ¨ Collision points reset.")
        
        # 'c' í‚¤ë¥¼ ëˆŒëŸ¬ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ ì‹œì‘/ë¦¬ì…‹
        elif key == ord('c'):
            is_calibrating = True
            counter = 0
            circles.fill(0)
            print("\nğŸ”„ CALIBRATION MODE: Please click 4 new points on the 'Original Image' window.")
            print("Order: Top-Left -> Top-Right -> Bottom-Left -> Bottom-Right")

        if key == ord('q'):
            break
finally:
    print("Stopping RealSense camera...")
    pipeline.stop()
    cv2.destroyAllWindows()