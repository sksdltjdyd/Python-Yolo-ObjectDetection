import pyrealsense2 as rs
import numpy as np
import cv2
from ultralytics import YOLO
import pickle
import time
from collections import deque
from pythonosc import udp_client
import json

class UnrealFirstPersonTracker:
    def __init__(self):
        # === ê¸°ë³¸ ì„¤ì • ===
        self.cam_width, self.cam_height = 640, 480
        self.confidence = 0.70
        self.yolo_path = 'C:/Users/User/Documents/Git/Python-Yolo-ObjectDetection/Yolo-Weights/Ball.pt'  # YOLO ëª¨ë¸ ê²½ë¡œ
        self.calibration_file = 'unreal_calibration.json'
        
        # === ì–¸ë¦¬ì–¼ ì¢Œí‘œê³„ ì„¤ì • ===
        # ì‹¤ì œ ì¹´ë©”ë¼ ì„¤ì¹˜ ìœ„ì¹˜ (cm)
        self.camera_real_height = 170  # ëˆˆë†’ì´
        self.camera_real_distance = 300  # ë²½ì—ì„œ ê±°ë¦¬
        
        # ì–¸ë¦¬ì–¼ ìºë¦­í„° ì„¤ì • (ì–¸ë¦¬ì–¼ ë‹¨ìœ„ = cm)
        self.unreal_player_height = 170
        self.unreal_player_distance = 300
        
        # FOV ë§¤ì¹­
        self.camera_fov_h = 87  # RealSense D455 ìˆ˜í‰ FOV
        self.camera_fov_v = 58  # ìˆ˜ì§ FOV
        
        # === OSC ì„¤ì • ===
        self.osc_client = udp_client.SimpleUDPClient("127.0.0.1", 8000)
        print(f"OSC client ready: 127.0.0.1:8000")
        
        # === íŠ¸ë˜í‚¹ ë°ì´í„° ===
        self.tracking_history = deque(maxlen=20)
        self.collision_history = []
        self.last_collision_time = 0
        self.collision_cooldown = 0.5
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„°
        self.calibration_offset = np.array([0, 0, 0])
        self.calibration_scale = 1.0
        self.calibration_rotation = np.eye(3)
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í¬ì¸íŠ¸
        self.calibration_points = []
        self.warp_matrix = None
        self.inverse_warp_matrix = None
        
        # ë¡œë“œ ìº˜ë¦¬ë¸Œë ˆì´ì…˜
        self.load_calibration()
        
        # === RealSense ì´ˆê¸°í™” ===
        self.init_realsense()
        
        # === YOLO ëª¨ë¸ ë¡œë“œ ===
        self.init_yolo()
        
        # === ë””ìŠ¤í”Œë ˆì´ ===
        self.display_output = np.zeros((720, 1280, 3), np.uint8)
        self.is_calibrating = False
        self.calib_step = 0
        
    def init_realsense(self):
        """RealSense ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, self.cam_width, self.cam_height, rs.format.z16, 60)
        config.enable_stream(rs.stream.color, self.cam_width, self.cam_height, rs.format.bgr8, 60)
        
        try:
            profile = self.pipeline.start(config)
            self.align = rs.align(rs.stream.color)
            
            # ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°
            depth_profile = profile.get_stream(rs.stream.depth)
            self.depth_intrinsics = depth_profile.as_video_stream_profile().get_intrinsics()
            
            print("âœ… RealSense initialized")
            
            # ì´ˆê¸° ì„¤ì • ì–¸ë¦¬ì–¼ë¡œ ì „ì†¡
            self.send_camera_settings()
            
        except Exception as e:
            print(f"âŒ RealSense init failed: {e}")
            exit(1)
    
    def init_yolo(self):
        """YOLO ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            self.model = YOLO(self.yolo_path)
            print(f"âœ… YOLO model loaded: {self.yolo_path}")
        except:
            self.model = YOLO('C:/Users/User/Documents/Git/Python-Yolo-ObjectDetection/Yolo-Weights/Ball.pt')
            print("âš ï¸ Using default YOLOv8n model")
    
    def send_camera_settings(self):
        """ì–¸ë¦¬ì–¼ì— ì¹´ë©”ë¼ ì„¤ì • ì „ì†¡"""
        settings = {
            'fov_horizontal': self.camera_fov_h,
            'fov_vertical': self.camera_fov_v,
            'camera_height': self.unreal_player_height,
            'camera_distance': self.unreal_player_distance
        }
        
        # ì¹´ë©”ë¼ ì„¤ì • ì „ì†¡
        self.osc_client.send_message("/camera/settings", [
            float(settings['fov_horizontal']),
            float(settings['fov_vertical']),
            float(settings['camera_height']),
            float(settings['camera_distance'])
        ])
        
        print(f"ğŸ“¡ Sent camera settings to Unreal: FOV={self.camera_fov_h}Â°, Height={self.unreal_player_height}cm")
    
    def realsense_to_unreal_coords(self, rs_x, rs_y, rs_z):
        """
        RealSense ì¢Œí‘œë¥¼ ì–¸ë¦¬ì–¼ 1ì¸ì¹­ ì¢Œí‘œë¡œ ë³€í™˜
        RealSense: X(right), Y(down), Z(forward) - ë¯¸í„°
        Unreal: X(forward), Y(right), Z(up) - ì„¼í‹°ë¯¸í„°
        """
        # ê¸°ë³¸ ë³€í™˜ (ë¯¸í„° -> ì„¼í‹°ë¯¸í„°)
        point = np.array([rs_x * 100, rs_y * 100, rs_z * 100])
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì ìš©
        point = point * self.calibration_scale
        point = np.dot(self.calibration_rotation, point)
        point = point + self.calibration_offset
        
        # ì–¸ë¦¬ì–¼ ì¢Œí‘œê³„ë¡œ ë§¤í•‘
        unreal_x = point[2]  # Z -> X (ì „ë°©)
        unreal_y = point[0]  # X -> Y (ìš°ì¸¡)
        unreal_z = -point[1] + self.unreal_player_height  # -Y -> Z (ìƒí•˜, í”Œë ˆì´ì–´ ë†’ì´ ê¸°ì¤€)
        
        return [unreal_x, unreal_y, unreal_z]
    
    def pixel_to_3d_point(self, x, y, depth_frame):
        """í”½ì…€ ì¢Œí‘œë¥¼ 3D ì›”ë“œ ì¢Œí‘œë¡œ ë³€í™˜"""
        depth = depth_frame.get_distance(int(x), int(y))
        if depth == 0:
            return None
        
        # RealSense 3D ì¢Œí‘œ (ë¯¸í„°)
        point_3d = rs.rs2_deproject_pixel_to_point(self.depth_intrinsics, [x, y], depth)
        
        # ì–¸ë¦¬ì–¼ ì¢Œí‘œë¡œ ë³€í™˜
        unreal_coords = self.realsense_to_unreal_coords(point_3d[0], point_3d[1], point_3d[2])
        
        return unreal_coords
    
    def detect_ball(self, img):
        """YOLOë¡œ ê³µ ê²€ì¶œ"""
        results = self.model(img, stream=False, verbose=False, conf=self.confidence)
        detections = []
        
        for r in results:
            if r.boxes is not None:
                for box in r.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    cx = (x1 + x2) // 2
                    cy = (y1 + y2) // 2
                    
                    # ì‹œê°í™”
                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(img, f"Ball {float(box.conf[0]):.2f}", 
                               (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                    
                    detections.append({
                        'center': (cx, cy),
                        'bbox': (x1, y1, x2, y2),
                        'confidence': float(box.conf[0])
                    })
        
        return img, detections
    
    def detect_collision(self, current_pos_3d):
        """ì¶©ëŒ ê°ì§€ ë¡œì§"""
        current_time = time.time()
        
        # ì¿¨ë‹¤ìš´ ì²´í¬
        if current_time - self.last_collision_time < self.collision_cooldown:
            return False
        
        # íŠ¸ë˜í‚¹ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.tracking_history.append({
            'position': current_pos_3d,
            'time': current_time
        })
        
        # ì¶©ëŒ ê°ì§€: ì†ë„ ê¸‰ë³€
        if len(self.tracking_history) >= 5:
            recent = list(self.tracking_history)[-5:]
            
            # Zì¶•(ì „ë°©) ì†ë„ ê³„ì‚°
            velocities = []
            for i in range(1, len(recent)):
                dt = recent[i]['time'] - recent[i-1]['time']
                if dt > 0:
                    dz = recent[i]['position'][0] - recent[i-1]['position'][0]  # Xì¶•ì´ ì „ë°©
                    v = dz / dt
                    velocities.append(v)
            
            if len(velocities) >= 2:
                # ê°€ì†ë„ ê³„ì‚°
                acceleration = velocities[-1] - velocities[-2]
                
                # ê¸‰ê²©í•œ ê°ì† = ì¶©ëŒ
                if acceleration < -500:  # cm/sÂ² ì„ê³„ê°’
                    self.last_collision_time = current_time
                    return True
        
        return False
    
    def send_to_unreal(self, position, is_collision=False):
        """ì–¸ë¦¬ì–¼ë¡œ ë°ì´í„° ì „ì†¡"""
        try:
            if is_collision:
                # ì¶©ëŒ ì´ë²¤íŠ¸
                self.osc_client.send_message("/ball/collision", [
                    float(position[0]),  # X (forward)
                    float(position[1]),  # Y (right)
                    float(position[2]),  # Z (up)
                    time.time()         # timestamp
                ])
                print(f"ğŸ’¥ Collision sent: X={position[0]:.1f}, Y={position[1]:.1f}, Z={position[2]:.1f}")
            else:
                # ìœ„ì¹˜ ì—…ë°ì´íŠ¸
                self.osc_client.send_message("/ball/position", [
                    float(position[0]),
                    float(position[1]),
                    float(position[2])
                ])
        except Exception as e:
            print(f"OSC error: {e}")
    
    def calibrate_space(self, event, x, y, flags, param):
        """ê³µê°„ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë§ˆìš°ìŠ¤ ì½œë°±"""
        if event == cv2.EVENT_LBUTTONDOWN and self.is_calibrating:
            self.calibration_points.append([x, y])
            print(f"Calibration point {len(self.calibration_points)}: ({x}, {y})")
            
            if len(self.calibration_points) == 4:
                # Warp ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
                pts1 = np.float32(self.calibration_points)
                pts2 = np.float32([[0, 0], [self.cam_width, 0], 
                                  [0, self.cam_height], [self.cam_width, self.cam_height]])
                
                self.warp_matrix = cv2.getPerspectiveTransform(pts1, pts2)
                self.inverse_warp_matrix = cv2.getPerspectiveTransform(pts2, pts1)
                
                self.save_calibration()
                self.is_calibrating = False
                self.calibration_points = []
                print("âœ… Calibration complete!")
    
    def manual_offset_adjustment(self, key):
        """ìˆ˜ë™ ì˜¤í”„ì…‹ ì¡°ì •"""
        adjustment = 5  # cm
        
        if key == ord('i'):  # Forward
            self.calibration_offset[0] += adjustment
        elif key == ord('k'):  # Backward
            self.calibration_offset[0] -= adjustment
        elif key == ord('j'):  # Left
            self.calibration_offset[1] -= adjustment
        elif key == ord('l'):  # Right
            self.calibration_offset[1] += adjustment
        elif key == ord('u'):  # Up
            self.calibration_offset[2] += adjustment
        elif key == ord('o'):  # Down
            self.calibration_offset[2] -= adjustment
        
        print(f"Offset adjusted: {self.calibration_offset}")
        self.save_calibration()
    
    def save_calibration(self):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ì €ì¥"""
        data = {
            'offset': self.calibration_offset.tolist(),
            'scale': self.calibration_scale,
            'rotation': self.calibration_rotation.tolist(),
            'warp_matrix': self.warp_matrix.tolist() if self.warp_matrix is not None else None,
            'inverse_warp_matrix': self.inverse_warp_matrix.tolist() if self.inverse_warp_matrix is not None else None
        }
        
        with open(self.calibration_file, 'w') as f:
            json.dump(data, f, indent=2)
        print(f"âœ… Calibration saved to {self.calibration_file}")
    
    def load_calibration(self):
        """ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(self.calibration_file, 'r') as f:
                data = json.load(f)
            
            self.calibration_offset = np.array(data['offset'])
            self.calibration_scale = data['scale']
            self.calibration_rotation = np.array(data['rotation'])
            
            if data['warp_matrix']:
                self.warp_matrix = np.array(data['warp_matrix'])
                self.inverse_warp_matrix = np.array(data['inverse_warp_matrix'])
            
            print(f"âœ… Calibration loaded from {self.calibration_file}")
        except:
            print("âš ï¸ No calibration file found, using defaults")
    
    def run(self):
        """ë©”ì¸ ë£¨í”„"""
        cv2.namedWindow("RealSense Tracking")
        cv2.setMouseCallback("RealSense Tracking", self.calibrate_space)
        
        fps_timer = time.time()
        fps_count = 0
        fps = 0
        
        print("\n" + "="*50)
        print("CONTROLS:")
        print("C - Start calibration (click 4 corners)")
        print("I/K - Forward/Backward offset")
        print("J/L - Left/Right offset")
        print("U/O - Up/Down offset")
        print("R - Reset collision points")
        print("Q - Quit")
        print("="*50 + "\n")
        
        while True:
            # í”„ë ˆì„ íšë“
            frames = self.pipeline.wait_for_frames()
            aligned_frames = self.align.process(frames)
            
            depth_frame = aligned_frames.get_depth_frame()
            color_frame = aligned_frames.get_color_frame()
            
            if not depth_frame or not color_frame:
                continue
            
            depth_image = np.asanyarray(depth_frame.get_data())
            color_image = np.asanyarray(color_frame.get_data())
            
            # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ëª¨ë“œ
            if self.is_calibrating:
                for i, pt in enumerate(self.calibration_points):
                    cv2.circle(color_image, tuple(pt), 5, (0, 255, 0), -1)
                    cv2.putText(color_image, str(i+1), (pt[0]-10, pt[1]-10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                cv2.putText(color_image, f"CALIBRATING: Click {4-len(self.calibration_points)} more corners",
                           (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            else:
                # Warp ì ìš© (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ëœ ê²½ìš°)
                if self.warp_matrix is not None:
                    warped_color = cv2.warpPerspective(color_image, self.warp_matrix, 
                                                       (self.cam_width, self.cam_height))
                else:
                    warped_color = color_image.copy()
                
                # ê³µ ê²€ì¶œ
                detected_img, balls = self.detect_ball(warped_color)
                
                if balls:
                    # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê³µ ì„ íƒ
                    best_ball = max(balls, key=lambda x: x['confidence'])
                    
                    # ì›ë³¸ ì¢Œí‘œë¡œ ì—­ë³€í™˜
                    if self.inverse_warp_matrix is not None:
                        warped_pt = np.array([[best_ball['center']]], dtype=np.float32)
                        original_pt = cv2.perspectiveTransform(warped_pt, self.inverse_warp_matrix)
                        cx, cy = original_pt[0][0]
                    else:
                        cx, cy = best_ball['center']
                    
                    # 3D ì¢Œí‘œ ê³„ì‚°
                    pos_3d = self.pixel_to_3d_point(cx, cy, depth_frame)
                    
                    if pos_3d:
                        # ì–¸ë¦¬ì–¼ë¡œ ìœ„ì¹˜ ì „ì†¡
                        self.send_to_unreal(pos_3d, is_collision=False)
                        
                        # ì¶©ëŒ ì²´í¬
                        if self.detect_collision(pos_3d):
                            self.send_to_unreal(pos_3d, is_collision=True)
                            
                            # ì¶©ëŒ ì‹œê°í™”
                            collision_point = (int(cx), int(cy))
                            self.collision_history.append(collision_point)
                        
                        # ì •ë³´ í‘œì‹œ
                        info_text = f"3D: X={pos_3d[0]:.0f} Y={pos_3d[1]:.0f} Z={pos_3d[2]:.0f}"
                        cv2.putText(color_image, info_text, (20, 100),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
                
                # Warped ë·° í‘œì‹œ
                if self.warp_matrix is not None:
                    cv2.imshow("Warped View", detected_img)
            
            # ì¶©ëŒ í¬ì¸íŠ¸ í‘œì‹œ
            for pt in self.collision_history[-10:]:  # ìµœê·¼ 10ê°œ
                cv2.circle(color_image, pt, 10, (0, 0, 255), -1)
            
            # FPS ê³„ì‚°
            fps_count += 1
            if time.time() - fps_timer >= 1.0:
                fps = fps_count
                fps_count = 0
                fps_timer = time.time()
            
            # ì •ë³´ í‘œì‹œ
            cv2.putText(color_image, f"FPS: {fps}", (20, 40),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            cv2.putText(color_image, f"Offset: {self.calibration_offset}", (20, 70),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            
            # ê¹Šì´ ë§µ ì»¬ëŸ¬
            depth_colormap = cv2.applyColorMap(
                cv2.convertScaleAbs(depth_image, alpha=0.03),
                cv2.COLORMAP_JET
            )
            
            # í™”ë©´ í‘œì‹œ
            combined = np.hstack([color_image, depth_colormap])
            cv2.imshow("RealSense Tracking", combined)
            
            # í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord('c'):
                self.is_calibrating = True
                self.calibration_points = []
                print("ğŸ¯ Calibration mode - click 4 corners")
            elif key == ord('r'):
                self.collision_history = []
                self.tracking_history.clear()
                print("âœ¨ Reset")
            elif key in [ord('i'), ord('k'), ord('j'), ord('l'), ord('u'), ord('o')]:
                self.manual_offset_adjustment(key)
        
        # ì¢…ë£Œ
        self.pipeline.stop()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    tracker = UnrealFirstPersonTracker()
    tracker.run()