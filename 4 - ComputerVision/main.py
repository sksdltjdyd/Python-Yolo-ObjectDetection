import pyrealsense2 as rs
import numpy as np
import cv2
from ultralytics import YOLO
import pickle
import time
from collections import deque
from pythonosc import udp_client

class ImprovedBallTracker:
    def __init__(self):
        # ê¸°ë³¸ ì„¤ì •
        self.cam_width, self.cam_height = 640, 480
        self.confidence = 0.70
        self.yolo_path = "C:/Users/User/Documents/Git/Python-Yolo-ObjectDetection/Yolo-Weights/Ball.pt"
        self.calibration_file = 'realsense_calibration_data.p'
        self.scale = 3
        
        # OSC ì„¤ì •
        self.osc_client = udp_client.SimpleUDPClient("127.0.0.1", 8000)
        
        # ì¶”ì  ë°ì´í„°
        self.tracking_history = deque(maxlen=10)
        self.collision_cooldown = 0
        self.last_collision_time = 0
        self.collision_threshold = 50  # mm
        
        # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë¡œë“œ
        self.load_calibration()
        
        # RealSense ì´ˆê¸°í™”
        self.pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.depth, self.cam_width, self.cam_height, rs.format.z16, 60)
        config.enable_stream(rs.stream.color, self.cam_width, self.cam_height, rs.format.bgr8, 60)
        
        profile = self.pipeline.start(config)
        self.align = rs.align(rs.stream.color)
        self.depth_intrinsics = profile.get_stream(rs.stream.depth).as_video_stream_profile().get_intrinsics()
        
        # YOLO ëª¨ë¸
        self.model = YOLO(self.yolo_path)
        
        # ì¶œë ¥ ì´ë¯¸ì§€
        self.img_output = np.zeros((1080, 1920, 3), np.uint8)
        self.collision_points = []
        
    def load_calibration(self):
        try:
            with open(self.calibration_file, 'rb') as f:
                points = pickle.load(f)
            
            pts1 = np.float32(points)
            pts2 = np.float32([[0, 0], [self.cam_width, 0], 
                              [0, self.cam_height], [self.cam_width, self.cam_height]])
            self.matrix = cv2.getPerspectiveTransform(pts1, pts2)
            self.inverse_matrix = cv2.getPerspectiveTransform(pts2, pts1)
            print("âœ… Calibration loaded")
        except:
            print("âŒ Calibration file not found")
            # ê¸°ë³¸ê°’ ì„¤ì •
            self.matrix = np.eye(3)
            self.inverse_matrix = np.eye(3)
    
    def detect_ball(self, img):
        results = self.model(img, stream=False, verbose=False, conf=self.confidence)
        balls = []
        
        for r in results:
            if r.boxes is not None:
                for box in r.boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    cx = (x1 + x2) // 2
                    cy = (y1 + y2) // 2
                    
                    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    balls.append({'center': (cx, cy), 'conf': float(box.conf[0])})
        
        return img, balls
    
    def get_3d_position(self, x, y, depth_frame):
        """í”½ì…€ ì¢Œí‘œë¥¼ 3D ìœ„ì¹˜ë¡œ ë³€í™˜ (ì–¸ë¦¬ì–¼ ì¢Œí‘œê³„)"""
        depth = depth_frame.get_distance(int(x), int(y))
        if depth == 0:
            return None
        
        # RealSense 3D ì¢Œí‘œ (ë¯¸í„°)
        point_3d = rs.rs2_deproject_pixel_to_point(self.depth_intrinsics, [x, y], depth)
        
        # ì–¸ë¦¬ì–¼ ì¢Œí‘œê³„ë¡œ ë³€í™˜ (ì„¼í‹°ë¯¸í„°)
        # RealSense: X(right), Y(down), Z(forward)
        # Unreal: X(forward), Y(right), Z(up)
        unreal_x = point_3d[2] * 100  # Z â†’ X (forward)
        unreal_y = point_3d[0] * 100  # X â†’ Y (right)
        unreal_z = -point_3d[1] * 100  # -Y â†’ Z (up)
        
        return [unreal_x, unreal_y, unreal_z]
    
    def detect_collision(self, ball_pos, depth_frame):
        """ê°œì„ ëœ ì¶©ëŒ ê°ì§€"""
        current_time = time.time()
        
        # ì¿¨ë‹¤ìš´ ì²´í¬
        if current_time - self.last_collision_time < 0.5:
            return False
        
        # 3D ìœ„ì¹˜ íšë“
        pos_3d = self.get_3d_position(ball_pos[0], ball_pos[1], depth_frame)
        if not pos_3d:
            return False
        
        # ì¶”ì  íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.tracking_history.append({
            'pos_2d': ball_pos,
            'pos_3d': pos_3d,
            'time': current_time,
            'depth': pos_3d[0]  # ì „ë°© ê±°ë¦¬
        })
        
        # ì¶©ëŒ ê°ì§€: ìµœì†Œ 5í”„ë ˆì„ ì´ìƒ ì¶”ì í–ˆê³ , ê¹Šì´ ë³€í™”ê°€ ê¸‰ê²©íˆ ë©ˆì¶¤
        if len(self.tracking_history) >= 5:
            recent = list(self.tracking_history)[-5:]
            depths = [h['depth'] for h in recent]
            
            # ì†ë„ ê³„ì‚°
            velocities = []
            for i in range(1, len(depths)):
                dt = recent[i]['time'] - recent[i-1]['time']
                if dt > 0:
                    v = (depths[i] - depths[i-1]) / dt
                    velocities.append(v)
            
            if velocities:
                # í‰ê·  ì†ë„ì™€ ê°€ì†ë„ ì²´í¬
                avg_velocity = np.mean(velocities[-3:]) if len(velocities) >= 3 else velocities[-1]
                
                # ë²½ì— ì ‘ê·¼ ì¤‘ì´ê³  ê°‘ìê¸° ë©ˆì¶¤
                if len(velocities) >= 2:
                    acceleration = velocities[-1] - velocities[-2]
                    
                    # ê¸‰ê²©í•œ ê°ì† = ì¶©ëŒ
                    if acceleration < -500 and abs(depths[-1] - depths[-2]) < self.collision_threshold:
                        self.last_collision_time = current_time
                        return True
        
        return False
    
    def send_osc_position(self, pos_3d, is_collision=False):
        """OSC ë©”ì‹œì§€ ì „ì†¡"""
        if not self.osc_client:
            return
        
        try:
            if is_collision:
                # ì¶©ëŒ ìœ„ì¹˜ ì „ì†¡
                self.osc_client.send_message("/ball/collision", [
                    float(pos_3d[0]),  # X
                    float(pos_3d[1]),  # Y
                    float(pos_3d[2]),  # Z
                    1.0  # ì¶©ëŒ ê°•ë„
                ])
                print(f"ğŸ’¥ Collision OSC: X={pos_3d[0]:.1f}, Y={pos_3d[1]:.1f}, Z={pos_3d[2]:.1f}")
            else:
                # ì¼ë°˜ ìœ„ì¹˜ ì „ì†¡
                self.osc_client.send_message("/ball/position", [
                    float(pos_3d[0]),
                    float(pos_3d[1]),
                    float(pos_3d[2])
                ])
        except Exception as e:
            print(f"OSC error: {e}")
    
    def run(self):
        fps_timer = time.time()
        fps_count = 0
        fps = 0
        
        while True:
            frames = self.pipeline.wait_for_frames()
            aligned_frames = self.align.process(frames)
            
            color_frame = aligned_frames.get_color_frame()
            depth_frame = aligned_frames.get_depth_frame()
            
            if not color_frame or not depth_frame:
                continue
            
            img = np.asanyarray(color_frame.get_data())
            
            # Warp image
            img_warped = cv2.warpPerspective(img, self.matrix, (self.cam_width, self.cam_height))
            
            # Detect balls
            img_detected, balls = self.detect_ball(img_warped)
            
            if balls:
                # ê°€ì¥ confidence ë†’ì€ ê³µ ì„ íƒ
                best_ball = max(balls, key=lambda x: x['conf'])
                warped_center = best_ball['center']
                
                # ì›ë³¸ ì¢Œí‘œë¡œ ì—­ë³€í™˜
                warped_pt = np.array([[warped_center]], dtype=np.float32)
                original_pt = cv2.perspectiveTransform(warped_pt, self.inverse_matrix)
                original_x, original_y = original_pt[0][0]
                
                # 3D ìœ„ì¹˜ ê³„ì‚°
                pos_3d = self.get_3d_position(original_x, original_y, depth_frame)
                
                if pos_3d:
                    # ìœ„ì¹˜ ì „ì†¡
                    self.send_osc_position(pos_3d, is_collision=False)
                    
                    # ì¶©ëŒ ì²´í¬
                    if self.detect_collision((original_x, original_y), depth_frame):
                        # ì¶©ëŒ ê°ì§€ë¨
                        self.send_osc_position(pos_3d, is_collision=True)
                        
                        # ì‹œê°í™”ìš© ì¶©ëŒ í¬ì¸íŠ¸ ì¶”ê°€
                        collision_x = int(warped_center[0] * self.scale)
                        collision_y = int(warped_center[1] * self.scale)
                        self.collision_points.append((collision_x, collision_y))
            
            # ì¶©ëŒ í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°
            for pt in self.collision_points:
                cv2.circle(self.img_output, pt, 15, (0, 0, 255), -1)
                cv2.circle(self.img_output, pt, 20, (0, 0, 200), 2)
            
            # FPS ê³„ì‚°
            fps_count += 1
            if time.time() - fps_timer >= 1.0:
                fps = fps_count
                fps_count = 0
                fps_timer = time.time()
            
            # í™”ë©´ í‘œì‹œ
            cv2.putText(img, f"FPS: {fps}", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.imshow("Original", img)
            cv2.imshow("Warped", img_detected)
            cv2.imshow("Collisions", self.img_output)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('r'):
                self.img_output.fill(0)
                self.collision_points.clear()
                self.tracking_history.clear()
                print("âœ¨ Reset")
        
        self.pipeline.stop()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    tracker = ImprovedBallTracker()
    tracker.run()